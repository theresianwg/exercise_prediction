{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1c5M0939zhX"
      },
      "source": [
        "# Import and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xxxB6s6qPGY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj2R2IqksEIR"
      },
      "outputs": [],
      "source": [
        "file_path = 'https://drive.google.com/uc?id=1w69PKv1mSGzy70yYBQ2W0nBwtWq-bKzh'\n",
        "file_path_pred = 'https://drive.google.com/uc?id=1pbpfNmlJjn3f7iG9IZAnu9U0yv-y1Aa_'\n",
        "\n",
        "# Load the first dataset (with 'targetnya' column)\n",
        "data_with_target = pd.read_csv(file_path, delimiter=\";\")\n",
        "\n",
        "# Load the second dataset (without 'targetnya' column)\n",
        "data_to_predict = pd.read_csv(file_path_pred, delimiter=\";\")\n",
        "\n",
        "data_to_predict = data_to_predict.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_qS5pn098ft"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObW3K8FI-CPK"
      },
      "source": [
        "## Null Values in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "E8i6bz0C-Nnu",
        "outputId": "aad1d927-076e-4fb5-c481-dbd8637ce34f"
      },
      "outputs": [],
      "source": [
        "data_with_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "EsVopichzzkE",
        "outputId": "cb0cd4ec-baef-4ab9-86ad-84010be6ddbd"
      },
      "outputs": [],
      "source": [
        "tmp = data_with_target.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "labels = tmp.index.to_list()\n",
        "values = tmp.to_list()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.title(\"Count Null Values in Dataset\")\n",
        "container = plt.bar(labels, values)\n",
        "plt.bar_label(container)\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
        "plt.ylabel(\"Number of Occurences\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxFIsRyu_Qam"
      },
      "source": [
        "### Solution\n",
        "Handle missing values before using it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsM3eb_B_HfZ"
      },
      "source": [
        "## Heat Map / Correlation Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n2BywozP7gYC",
        "outputId": "8ac0b751-b326-456e-bae8-fe077c4ef026"
      },
      "outputs": [],
      "source": [
        "# Copy dataframe\n",
        "data_corr = pd.concat([valid_data, invalid_data])\n",
        "\n",
        "# Change all column to be numeric\n",
        "for column in data_corr.columns:\n",
        "    le = LabelEncoder()\n",
        "    data_corr[column] = le.fit_transform(data_corr[column])\n",
        "\n",
        "# Create Heat Map\n",
        "data_corr = data_corr.corr()\n",
        "data_corr = round(data_corr, 3)\n",
        "plt.figure(figsize=(35, 25))\n",
        "plt.title(\"Heat Map Correlation\", fontsize=25, pad=20)\n",
        "sns.heatmap(data_corr,annot=True,cmap=\"RdYlGn\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "UbxP9Bkd8e0u",
        "outputId": "2c835068-17c0-4ae5-dafc-63a5976186e4"
      },
      "outputs": [],
      "source": [
        "# Descending correlation values to \"type of attack\" column / target column\n",
        "tmp = data_corr.drop([\"targetnya\"])\n",
        "tmp = tmp[['targetnya']]\n",
        "tmp = tmp['targetnya'].fillna(0)\n",
        "tmp = tmp.sort_values(ascending=False)\n",
        "\n",
        "# Barchart Ilustration\n",
        "labels = tmp.index.to_list()\n",
        "values_pos = tmp[tmp >= 0].to_list()\n",
        "values_neg = tmp[tmp < 0].to_list()\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "# plt.title(f'{values_col} at {datte} for each region')\n",
        "container = plt.bar(labels[:len(values_pos)], values_pos, color=\"green\")\n",
        "container2 = plt.bar(labels[len(values_pos):], values_neg, color=\"red\")\n",
        "plt.bar_label(container)\n",
        "plt.bar_label(container2)\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
        "plt.ylabel('Correlation to Target Column')\n",
        "plt.title(\"Data Column Corellation to Target Column (targetnya)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrWMPXTRAVXD"
      },
      "source": [
        "### Solution\n",
        "There are sufficient column with enough correlation to the target column for Feature Selection scenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OofvLS8o5hc2"
      },
      "source": [
        "## Target Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "QmDU_JID5tWq",
        "outputId": "b96c4a43-c5ea-4c99-bb06-72a0d1d2343b"
      },
      "outputs": [],
      "source": [
        "tmp = data_with_target['targetnya']\n",
        "tmp = tmp.value_counts()\n",
        "\n",
        "labels = tmp.index.to_list()\n",
        "values = tmp.to_list()\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "container = plt.bar(labels, values)\n",
        "plt.bar_label(container)\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation=90)\n",
        "plt.ylabel(\"Number of Occurences\")\n",
        "plt.title(\"Number of Data\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(values, labels=labels, autopct='%.1f%%', center=(0, 0))\n",
        "plt.title(\"Proportion of Data\", pad=40)\n",
        "\n",
        "plt.suptitle(\"Distribution of Target Data\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upl_dgEp6vJ1"
      },
      "source": [
        "### Solution\n",
        "Because of the imbalance of the target data distribution, we have the option to do either oversampling or undersampling to our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1neOUVWx-G1W"
      },
      "source": [
        "# Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNpKbFCo7eFL"
      },
      "outputs": [],
      "source": [
        "file_path = 'https://drive.google.com/uc?id=1w69PKv1mSGzy70yYBQ2W0nBwtWq-bKzh'\n",
        "file_path_pred = 'https://drive.google.com/uc?id=1pbpfNmlJjn3f7iG9IZAnu9U0yv-y1Aa_'\n",
        "\n",
        "# Load the first dataset (with 'targetnya' column)\n",
        "data_with_target = pd.read_csv(file_path, delimiter=\";\")\n",
        "\n",
        "# Load the second dataset (without 'targetnya' column)\n",
        "data_to_predict = pd.read_csv(file_path_pred, delimiter=\";\")\n",
        "\n",
        "data_to_predict = data_to_predict.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RKkgdZusJmn"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "# Handle missing values\n",
        "data_with_target.drop_duplicates(inplace=True)\n",
        "data_with_target.replace('*', np.nan, inplace=True)\n",
        "data_with_target.replace(\"99999\", np.nan, inplace=True)\n",
        "data_with_target.replace(99999, np.nan, inplace=True)\n",
        "data_with_target.replace(99999.00, np.nan, inplace=True)\n",
        "\n",
        "# Handle NaN values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_with_target = pd.DataFrame(imputer.fit_transform(data_with_target), columns=data_with_target.columns)\n",
        "# data_to_predict = pd.DataFrame(imputer.transform(data_to_predict), columns=data_to_predict.columns)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_with_target[column] = le.fit_transform(data_with_target[column])\n",
        "    data_to_predict[column] = le.transform(data_to_predict[column])\n",
        "    label_encoders[column] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrXgiMhAsKLH"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X = data_with_target.drop(columns=['targetnya'])\n",
        "y = data_with_target['targetnya']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHRK_G9-tIBJ"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "MwgqZtn0sP6v",
        "outputId": "053da04d-3c0f-4f35-9dda-09da7dafc49f"
      },
      "outputs": [],
      "source": [
        "# Train a Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJA_Ttx6sR1X",
        "outputId": "3fded861-cbd5-42f1-9c30-810055b944ca"
      },
      "outputs": [],
      "source": [
        "# Predict on the testing set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyoBpkwvtC3R"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0srfGA_jtZ6I"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Bts3hyvGtRG2",
        "outputId": "7a708f18-bdd3-47d6-fab4-cf5af5240acd"
      },
      "outputs": [],
      "source": [
        "# Train a Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwIoHySdtezI"
      },
      "outputs": [],
      "source": [
        "# Predict on the testing set\n",
        "y_pred = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0Xk7LbGtgqK"
      },
      "outputs": [],
      "source": [
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUQy-438tkZa",
        "outputId": "c617b8e1-5359-4fde-e310-71eb4f01c83c"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgABzjvIFa4h"
      },
      "source": [
        "##Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syQBCy_RFd-V"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suGmzo3VFls2"
      },
      "outputs": [],
      "source": [
        "# # Standardize numerical features\n",
        "# scaler = StandardScaler()\n",
        "# data_with_target[data_with_target.columns[:-1]] = scaler.fit_transform(data_with_target[data_with_target.columns[:-1]])\n",
        "# data_to_predict[data_to_predict.columns] = scaler.transform(data_to_predict[data_to_predict.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxt10jqWQfyw",
        "outputId": "1e379de2-9d86-4318-b36d-7665282ff72f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-374-efe427368b27>:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train_tf = np.asarray(X_train).astype(np.float)\n",
            "<ipython-input-374-efe427368b27>:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_test_tf = np.asarray(X_test).astype(np.float)\n"
          ]
        }
      ],
      "source": [
        "# Change data type for keras process\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_tf = label_encoder.fit_transform(y_train)\n",
        "y_test_tf = label_encoder.transform(y_test)\n",
        "\n",
        "X_train_tf = np.asarray(X_train).astype(np.float)\n",
        "X_test_tf = np.asarray(X_test).astype(np.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3t7BZDkF0-y",
        "outputId": "273c75c3-8edb-4307-a0be-620540fe6a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2776/2776 [==============================] - 8s 2ms/step - loss: 11067.9375 - accuracy: 0.9016 - val_loss: 103.2262 - val_accuracy: 0.9407\n",
            "Epoch 2/10\n",
            "2776/2776 [==============================] - 7s 3ms/step - loss: 2559.6589 - accuracy: 0.8905 - val_loss: 4042.1934 - val_accuracy: 0.8593\n",
            "Epoch 3/10\n",
            "2776/2776 [==============================] - 6s 2ms/step - loss: 1701.5894 - accuracy: 0.9045 - val_loss: 169.6131 - val_accuracy: 0.9361\n",
            "Epoch 4/10\n",
            "2776/2776 [==============================] - 8s 3ms/step - loss: 3501.4961 - accuracy: 0.9167 - val_loss: 1363.3981 - val_accuracy: 0.9230\n",
            "Epoch 5/10\n",
            "2776/2776 [==============================] - 6s 2ms/step - loss: 1329.4614 - accuracy: 0.9199 - val_loss: 255.2859 - val_accuracy: 0.9079\n",
            "Epoch 6/10\n",
            "2776/2776 [==============================] - 8s 3ms/step - loss: 4353.3701 - accuracy: 0.8816 - val_loss: 2718.2915 - val_accuracy: 0.8580\n",
            "Epoch 7/10\n",
            "2776/2776 [==============================] - 7s 2ms/step - loss: 2726.9561 - accuracy: 0.8935 - val_loss: 3286.7788 - val_accuracy: 0.9026\n",
            "Epoch 8/10\n",
            "2776/2776 [==============================] - 7s 3ms/step - loss: 2210.2952 - accuracy: 0.9041 - val_loss: 2053.2153 - val_accuracy: 0.9138\n",
            "Epoch 9/10\n",
            "2776/2776 [==============================] - 6s 2ms/step - loss: 1985.3525 - accuracy: 0.9107 - val_loss: 2569.8840 - val_accuracy: 0.9226\n",
            "Epoch 10/10\n",
            "2776/2776 [==============================] - 7s 3ms/step - loss: 1268.4808 - accuracy: 0.9201 - val_loss: 771.4744 - val_accuracy: 0.9254\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78b4ec8dcd00>"
            ]
          },
          "execution_count": 375,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build a simple feedforward neural network using Keras\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train_tf.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(len(data_with_target[\"targetnya\"].unique()), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the neural network\n",
        "model.fit(X_train_tf, y_train_tf, epochs=10, batch_size=32, validation_data=(X_test_tf, y_test_tf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhb7IbgrRWOX",
        "outputId": "0b7666e7-a549-402e-f3f4-c929282f030f"
      },
      "outputs": [],
      "source": [
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test_tf)\n",
        "\n",
        "# Transform to the index with the maximum value\n",
        "tmp = []\n",
        "for i in range(len(y_pred)):\n",
        "  tmp.append(np.argmax(y_pred[i]))\n",
        "y_pred = tmp\n",
        "\n",
        "# Transform the label back\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "y_test_tf = label_encoder.inverse_transform(y_test_tf)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test_tf, y_pred, average='weighted')\n",
        "recall = recall_score(y_test_tf, y_pred,  average='weighted')\n",
        "f1 = f1_score(y_test_tf, y_pred, average='weighted')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test_tf, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaSW0eE3NnP3"
      },
      "source": [
        "##Ensemble Learning (Adaboost+RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b9hLDQDNw32"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWm7qM67Np7R",
        "outputId": "e99587ad-6033-4550-913e-0352b594452f"
      },
      "outputs": [],
      "source": [
        "# Create base estimators for the ensemble\n",
        "base_estimator_1 = DecisionTreeClassifier(max_depth=3)\n",
        "base_estimator_2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create the ensemble with AdaBoost and Random Forest\n",
        "ada_boost_classifier = AdaBoostClassifier(base_estimator=base_estimator_1, random_state=42)\n",
        "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "ensemble_classifier = VotingClassifier(estimators=[\n",
        "    ('AdaBoost', ada_boost_classifier),\n",
        "    ('RandomForest', random_forest_classifier)\n",
        "], voting='soft')  # 'soft' voting for probabilities\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = ensemble_classifier.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhkQ8QdJS7a4"
      },
      "source": [
        "## 4.1 Untreated + SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY89i-QANSeD"
      },
      "outputs": [],
      "source": [
        "file_path = 'https://drive.google.com/uc?id=1w69PKv1mSGzy70yYBQ2W0nBwtWq-bKzh'\n",
        "file_path_pred = 'https://drive.google.com/uc?id=1pbpfNmlJjn3f7iG9IZAnu9U0yv-y1Aa_'\n",
        "\n",
        "# Load the first dataset (with 'targetnya' column)\n",
        "data_with_target = pd.read_csv(file_path, delimiter=\";\")\n",
        "\n",
        "# Load the second dataset (without 'targetnya' column)\n",
        "data_to_predict = pd.read_csv(file_path_pred, delimiter=\";\")\n",
        "\n",
        "data_to_predict = data_to_predict.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "MvPyAJyKPu-_",
        "outputId": "c00c302b-9acb-4dff-b3b4-1cadf3c17231"
      },
      "outputs": [],
      "source": [
        "# Find all rows that contains faulty data (Null, 99999, *)\n",
        "train = data_with_target[(data_with_target['duration'] == \"99999\") | \\\n",
        "                  (data_with_target['duration'] == 99999) | \\\n",
        "                   (data_with_target['duration'] == 99999.00) | \\\n",
        "                    (data_with_target['duration'] == \"*\") | \\\n",
        "                    (data_with_target['duration'].isnull())]\n",
        "\n",
        "\n",
        "for col in data_with_target.columns[1:]:\n",
        "  tmp1 = data_with_target[(data_with_target[col] == \"99999\") | \\\n",
        "                  (data_with_target[col] == 99999) | \\\n",
        "                   (data_with_target[col] == 99999.00) | \\\n",
        "                    (data_with_target[col] == \"*\") | \\\n",
        "                    (data_with_target[col].isnull())]\n",
        "  train = pd.concat([train, tmp1])\n",
        "  train.drop_duplicates(inplace=True)\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "jS1mTapMPxHn",
        "outputId": "9aa1d97b-d929-41a2-a1ff-311dd87f56a9"
      },
      "outputs": [],
      "source": [
        "# Find all rows that contains non faulty data\n",
        "test = data_with_target.merge(train.drop_duplicates(),\n",
        "                   how='left', indicator=True)\n",
        "test = test[test['_merge'] == 'left_only']\n",
        "test.drop(columns=['_merge'], inplace=True)\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loor_S9MQHym",
        "outputId": "93dcad70-aead-4a7e-b842-8986e03b35e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(95239, 42) (15800, 42)\n",
            "1407\n",
            "\n",
            "112446\n",
            "(112446, 42)\n"
          ]
        }
      ],
      "source": [
        "# Validate split\n",
        "print(train.shape, test.shape)\n",
        "print(data_with_target.duplicated().sum())\n",
        "print()\n",
        "print(train.shape[0] + test.shape[0] + data_with_target.duplicated().sum())\n",
        "print(data_with_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBDKbaZBQSz5"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "# Handle missing values\n",
        "train.drop_duplicates(inplace=True)\n",
        "# train.replace('*', np.nan, inplace=True)\n",
        "# train.replace(\"99999\", np.nan, inplace=True)\n",
        "# train.replace(99999, np.nan, inplace=True)\n",
        "# train.replace(99999.00, np.nan, inplace=True)\n",
        "train.replace('*', \"99999\", inplace=True)\n",
        "\n",
        "test.drop_duplicates(inplace=True)\n",
        "# test.replace('*', np.nan, inplace=True)\n",
        "# test.replace(\"99999\", np.nan, inplace=True)\n",
        "# test.replace(99999, np.nan, inplace=True)\n",
        "# test.replace(99999.00, np.nan, inplace=True)\n",
        "train.replace('*', \"99999\", inplace=True)\n",
        "\n",
        "# Handle NaN values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_with_target = pd.DataFrame(imputer.fit_transform(data_with_target), columns=data_with_target.columns)\n",
        "train = pd.DataFrame(imputer.transform(train), columns=train.columns)\n",
        "test = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
        "\n",
        "# data_to_predict = pd.DataFrame(imputer.transform(data_to_predict), columns=data_to_predict.columns)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_with_target[column] = le.fit_transform(data_with_target[column])\n",
        "    train[column] = le.transform(train[column])\n",
        "    test[column] = le.transform(test[column])\n",
        "\n",
        "    data_to_predict[column] = le.transform(data_to_predict[column])\n",
        "    label_encoders[column] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy7UX6VlQWdC"
      },
      "outputs": [],
      "source": [
        "# Create X and y\n",
        "y_train = train['targetnya']\n",
        "X_train = train.drop(columns=['targetnya'])\n",
        "\n",
        "y_test = test['targetnya']\n",
        "X_test = test.drop(columns=['targetnya'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2qT3526NUPC",
        "outputId": "d1e1c83a-25d3-4136-cece-b5ea65047fc6"
      },
      "outputs": [],
      "source": [
        "# Length before oversampling\n",
        "print(Counter(train['targetnya']), len(train))\n",
        "print(Counter(test['targetnya']), len(test))\n",
        "\n",
        "# Oversampling\n",
        "ov = SMOTE(random_state=42)\n",
        "X_train, y_train = ov.fit_resample(X_train, y_train)\n",
        "X_test, y_test = ov.fit_resample(X_test, y_test)\n",
        "\n",
        "# Length after oversampling\n",
        "print(Counter(y_train), len(y_train))\n",
        "print(Counter(y_test), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7zaGXdKavFr"
      },
      "source": [
        "# Feature Selection correlation Threshold >= 0.1 or <= -0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0SBrbmpTa4S4"
      },
      "outputs": [],
      "source": [
        "file_path = 'https://drive.google.com/uc?id=1w69PKv1mSGzy70yYBQ2W0nBwtWq-bKzh'\n",
        "file_path_pred = 'https://drive.google.com/uc?id=1pbpfNmlJjn3f7iG9IZAnu9U0yv-y1Aa_'\n",
        "\n",
        "# Load the first dataset (with 'targetnya' column)\n",
        "data_with_target = pd.read_csv(file_path, delimiter=\";\")\n",
        "\n",
        "# Load the second dataset (without 'targetnya' column)\n",
        "data_to_predict = pd.read_csv(file_path_pred, delimiter=\";\")\n",
        "\n",
        "data_to_predict = data_to_predict.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pW3qB6ZjbBj-",
        "outputId": "aee63554-3e0f-4db3-d69f-b2ee1c008385"
      },
      "outputs": [],
      "source": [
        "# Find all rows that contains faulty data (Null, 99999, *)\n",
        "train = data_with_target[(data_with_target['duration'] == \"99999\") | \\\n",
        "                  (data_with_target['duration'] == 99999) | \\\n",
        "                   (data_with_target['duration'] == 99999.00) | \\\n",
        "                    (data_with_target['duration'] == \"*\") | \\\n",
        "                    (data_with_target['duration'].isnull())]\n",
        "\n",
        "\n",
        "for col in data_with_target.columns[1:]:\n",
        "  tmp1 = data_with_target[(data_with_target[col] == \"99999\") | \\\n",
        "                  (data_with_target[col] == 99999) | \\\n",
        "                   (data_with_target[col] == 99999.00) | \\\n",
        "                    (data_with_target[col] == \"*\") | \\\n",
        "                    (data_with_target[col].isnull())]\n",
        "  train = pd.concat([train, tmp1])\n",
        "  train.drop_duplicates(inplace=True)\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pWVgMvHQbCkG",
        "outputId": "5cc5fa8f-c2af-46d0-99db-ccc2d2499599"
      },
      "outputs": [],
      "source": [
        "# Find all rows that contains non faulty data\n",
        "test = data_with_target.merge(train.drop_duplicates(),\n",
        "                   how='left', indicator=True)\n",
        "test = test[test['_merge'] == 'left_only']\n",
        "test.drop(columns=['_merge'], inplace=True)\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rk-KpdyHbGu3",
        "outputId": "1fa4ea39-eabe-4d85-a304-f84b73e98a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(95239, 42) (15800, 42)\n",
            "1407\n",
            "\n",
            "112446\n",
            "(112446, 42)\n"
          ]
        }
      ],
      "source": [
        "# Validate split\n",
        "print(train.shape, test.shape)\n",
        "print(data_with_target.duplicated().sum())\n",
        "print()\n",
        "print(train.shape[0] + test.shape[0] + data_with_target.duplicated().sum())\n",
        "print(data_with_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CWA9LVhjbJFE"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "# Handle missing values\n",
        "train.drop_duplicates(inplace=True)\n",
        "train.replace('*', np.nan, inplace=True)\n",
        "train.replace(\"99999\", np.nan, inplace=True)\n",
        "train.replace(99999, np.nan, inplace=True)\n",
        "train.replace(99999.00, np.nan, inplace=True)\n",
        "# train.replace('*', \"99999\", inplace=True)\n",
        "\n",
        "test.drop_duplicates(inplace=True)\n",
        "test.replace('*', np.nan, inplace=True)\n",
        "test.replace(\"99999\", np.nan, inplace=True)\n",
        "test.replace(99999, np.nan, inplace=True)\n",
        "test.replace(99999.00, np.nan, inplace=True)\n",
        "# train.replace('*', \"99999\", inplace=True)\n",
        "\n",
        "# Handle NaN values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_with_target = pd.DataFrame(imputer.fit_transform(data_with_target), columns=data_with_target.columns)\n",
        "train = pd.DataFrame(imputer.transform(train), columns=train.columns)\n",
        "test = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
        "\n",
        "# data_to_predict = pd.DataFrame(imputer.transform(data_to_predict), columns=data_to_predict.columns)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_with_target[column] = le.fit_transform(data_with_target[column])\n",
        "    train[column] = le.transform(train[column])\n",
        "    test[column] = le.transform(test[column])\n",
        "\n",
        "    data_to_predict[column] = le.transform(data_to_predict[column])\n",
        "    label_encoders[column] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CAMYMn2sbL5N",
        "outputId": "76b0d823-f1ac-4758-b3be-0d2a15684434"
      },
      "outputs": [],
      "source": [
        "# Copy dataframe\n",
        "data_corr = pd.concat([train, test])\n",
        "\n",
        "# Change all column to be numeric\n",
        "for column in data_corr.columns:\n",
        "    le = LabelEncoder()\n",
        "    data_corr[column] = le.fit_transform(data_corr[column])\n",
        "\n",
        "# Create Correlation\n",
        "data_corr = data_corr.corr()\n",
        "data_corr = round(data_corr, 3)\n",
        "\n",
        "# Create Heat Map\n",
        "plt.figure(figsize=(35, 25))\n",
        "plt.title(\"Heat Map Correlation after Preprocessing\", fontsize=25, pad=20)\n",
        "sns.heatmap(data_corr,annot=True,cmap=\"RdYlGn\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q_PUilIsrANn",
        "outputId": "6135fe73-07c4-4e1d-8416-4f9807ecdf57"
      },
      "outputs": [],
      "source": [
        "# Descending correlation values to \"type of attack\" column / target column\n",
        "tmp = data_corr.drop([\"targetnya\"])\n",
        "tmp = tmp[['targetnya']]\n",
        "tmp = tmp['targetnya'].fillna(0)\n",
        "tmp = tmp.sort_values(ascending=False)\n",
        "\n",
        "# Barchart Ilustration\n",
        "labels = tmp.index.to_list()\n",
        "values_pos = tmp[tmp >= 0].to_list()\n",
        "values_neg = tmp[tmp < 0].to_list()\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "# plt.title(f'{values_col} at {datte} for each region')\n",
        "container = plt.bar(labels[:len(values_pos)], values_pos, color=\"green\")\n",
        "container2 = plt.bar(labels[len(values_pos):], values_neg, color=\"red\")\n",
        "plt.bar_label(container)\n",
        "plt.bar_label(container2)\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
        "plt.ylabel('Correlation to Target Column')\n",
        "plt.title(\"Data Column Corellation to Target Column (targetnya)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6gDX-2WMbPKP",
        "outputId": "a7d4f9cb-b008-4401-c543-fd87853d6903"
      },
      "outputs": [],
      "source": [
        "# Descending correlation values to \"type of attack\" column / target column\n",
        "tmp = data_corr.drop([\"targetnya\"])\n",
        "tmp = tmp[['targetnya']]\n",
        "tmp['targetnya'].sort_values(ascending=False)\n",
        "\n",
        "# Capture columns that satisfy the threshold\n",
        "threshold = 0.1\n",
        "tmp = tmp[(tmp['targetnya'] >= threshold) | (tmp['targetnya'] <= -(threshold))]\n",
        "print(f\"length of valid columns = {len(tmp)}\")\n",
        "valid_columns = tmp.index\n",
        "tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gBZhNSHdbTDt",
        "outputId": "7a020f68-fb3b-4043-96c6-5978954aacb9"
      },
      "outputs": [],
      "source": [
        "# Only select target and valid columns\n",
        "tmp_col = list(valid_columns)\n",
        "tmp_col.append('targetnya')\n",
        "\n",
        "# Create Heat Map\n",
        "data_corr_val = data_corr[tmp_col]\n",
        "data_corr_val = data_corr_val.loc[tmp_col]\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title(\"Heat Map Correlation with only Valid Columns\")\n",
        "sns.heatmap(data_corr_val,annot=True,cmap=\"RdYlGn\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Th8XWCALbXe-",
        "outputId": "76e7b80b-9001-4d03-d498-7f92da748a27"
      },
      "outputs": [],
      "source": [
        "# Descending correlation values to \"type of attack\" column / target column\n",
        "tmp = tmp['targetnya']\n",
        "tmp = tmp.sort_values(ascending=False)\n",
        "\n",
        "# Barchart Ilustration\n",
        "labels = tmp.index.to_list()\n",
        "values_pos = tmp[tmp >= 0].to_list()\n",
        "values_neg = tmp[tmp < 0].to_list()\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "# plt.title(f'{values_col} at {datte} for each region')\n",
        "container = plt.bar(labels[:len(values_pos)], values_pos, color=\"green\")\n",
        "container2 = plt.bar(labels[len(values_pos):], values_neg, color=\"red\")\n",
        "plt.bar_label(container)\n",
        "plt.bar_label(container2)\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation = 'vertical')\n",
        "plt.ylabel('Correlation to Target Column')\n",
        "plt.title(\"Data Column Corellation to Target Column (targetnya)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xb79-gULbar6"
      },
      "outputs": [],
      "source": [
        "# Create X and y\n",
        "y_train = train['targetnya']\n",
        "X_train = train.drop(columns=['targetnya'])\n",
        "X_train = X_train[valid_columns]\n",
        "\n",
        "y_test = test['targetnya']\n",
        "X_test = test.drop(columns=['targetnya'])\n",
        "X_test = X_test[valid_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0HPiVbSIbfsn",
        "outputId": "f4914525-115f-4fc2-fa85-ecdbe32a79ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'normal': 47985, 'neptune': 36678, 'satan': 2819, 'ipsweep': 2781, 'portsweep': 1878, 'Denial of Service Attack': 1330, 'nmap': 955, 'smurf': 813}) 95239\n",
            "Counter({'normal': 12184, 'smurf': 1565, 'portsweep': 773, 'Denial of Service Attack': 416, 'nmap': 367, 'ipsweep': 255, 'neptune': 154, 'satan': 86}) 15800\n",
            "Counter({'normal': 47985, 'neptune': 47985, 'smurf': 47985, 'Denial of Service Attack': 47985, 'satan': 47985, 'portsweep': 47985, 'ipsweep': 47985, 'nmap': 47985}) 383880\n",
            "Counter({'nmap': 12184, 'normal': 12184, 'smurf': 12184, 'portsweep': 12184, 'ipsweep': 12184, 'Denial of Service Attack': 12184, 'neptune': 12184, 'satan': 12184}) 97472\n"
          ]
        }
      ],
      "source": [
        "# Length before oversampling\n",
        "print(Counter(train['targetnya']), len(train))\n",
        "print(Counter(test['targetnya']), len(test))\n",
        "\n",
        "# Oversampling\n",
        "ov = SMOTE(random_state=42)\n",
        "X_train, y_train = ov.fit_resample(X_train, y_train)\n",
        "X_test, y_test = ov.fit_resample(X_test, y_test)\n",
        "\n",
        "# Length after oversampling\n",
        "print(Counter(y_train), len(y_train))\n",
        "print(Counter(y_test), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmF-H4VJfwy7"
      },
      "source": [
        "# All Scenarios Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojydsQ-_jYTV"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdJMeIRjgXqk"
      },
      "outputs": [],
      "source": [
        "file_path = 'https://drive.google.com/uc?id=1w69PKv1mSGzy70yYBQ2W0nBwtWq-bKzh'\n",
        "file_path_pred = 'https://drive.google.com/uc?id=1pbpfNmlJjn3f7iG9IZAnu9U0yv-y1Aa_'\n",
        "\n",
        "# Load the first dataset (with 'targetnya' column)\n",
        "data_with_target = pd.read_csv(file_path, delimiter=\";\")\n",
        "\n",
        "# Load the second dataset (without 'targetnya' column)\n",
        "data_to_predict = pd.read_csv(file_path_pred, delimiter=\";\")\n",
        "\n",
        "data_to_predict = data_to_predict.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91TbP83TjbJ_"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "RRdjXJragfsj",
        "outputId": "338a0b19-6196-41e6-dbc7-4f7e898ff454"
      },
      "outputs": [],
      "source": [
        "# Find all rows that contains faulty data (Null, 99999, *)\n",
        "train = data_with_target[(data_with_target['duration'] == \"99999\") | \\\n",
        "                  (data_with_target['duration'] == 99999) | \\\n",
        "                   (data_with_target['duration'] == 99999.00) | \\\n",
        "                    (data_with_target['duration'] == \"*\") | \\\n",
        "                    (data_with_target['duration'].isnull())]\n",
        "\n",
        "\n",
        "for col in data_with_target.columns[1:]:\n",
        "  tmp1 = data_with_target[(data_with_target[col] == \"99999\") | \\\n",
        "                  (data_with_target[col] == 99999) | \\\n",
        "                   (data_with_target[col] == 99999.00) | \\\n",
        "                    (data_with_target[col] == \"*\") | \\\n",
        "                    (data_with_target[col].isnull())]\n",
        "  train = pd.concat([train, tmp1])\n",
        "  train.drop_duplicates(inplace=True)\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "jToFyHjSgiJd",
        "outputId": "f8326a8e-e245-42c9-9fea-78d009adcd96"
      },
      "outputs": [],
      "source": [
        "# Find all rows that contains non faulty data\n",
        "test = data_with_target.merge(train.drop_duplicates(),\n",
        "                   how='left', indicator=True)\n",
        "test = test[test['_merge'] == 'left_only']\n",
        "test.drop(columns=['_merge'], inplace=True)\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ngoSJc5gloT",
        "outputId": "164fdfb4-a403-433a-ee36-022f63215695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(95239, 42) (15800, 42)\n",
            "1407\n",
            "\n",
            "112446\n",
            "(112446, 42)\n"
          ]
        }
      ],
      "source": [
        "# Validate split\n",
        "print(train.shape, test.shape)\n",
        "print(data_with_target.duplicated().sum())\n",
        "print()\n",
        "print(train.shape[0] + test.shape[0] + data_with_target.duplicated().sum())\n",
        "print(data_with_target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4TN_yFYgp48"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "# Handle missing values\n",
        "train.drop_duplicates(inplace=True)\n",
        "train.replace('*', np.nan, inplace=True)\n",
        "train.replace(\"99999\", np.nan, inplace=True)\n",
        "train.replace(99999, np.nan, inplace=True)\n",
        "train.replace(99999.00, np.nan, inplace=True)\n",
        "# train.replace('*', \"99999\", inplace=True)\n",
        "\n",
        "test.drop_duplicates(inplace=True)\n",
        "test.replace('*', np.nan, inplace=True)\n",
        "test.replace(\"99999\", np.nan, inplace=True)\n",
        "test.replace(99999, np.nan, inplace=True)\n",
        "test.replace(99999.00, np.nan, inplace=True)\n",
        "# train.replace('*', \"99999\", inplace=True)\n",
        "\n",
        "# Handle NaN values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_with_target = pd.DataFrame(imputer.fit_transform(data_with_target), columns=data_with_target.columns)\n",
        "train = pd.DataFrame(imputer.transform(train), columns=train.columns)\n",
        "test = pd.DataFrame(imputer.transform(test), columns=test.columns)\n",
        "\n",
        "\n",
        "# data_to_predict = pd.DataFrame(imputer.transform(data_to_predict), columns=data_to_predict.columns)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data_with_target[column] = le.fit_transform(data_with_target[column])\n",
        "    train[column] = le.transform(train[column])\n",
        "    test[column] = le.transform(test[column])\n",
        "    data_to_predict[column] = le.transform(data_to_predict[column])\n",
        "    label_encoders[column] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuBBQMQ9gv0P"
      },
      "outputs": [],
      "source": [
        "# Create X and y\n",
        "y_train = train['targetnya']\n",
        "X_train = train.drop(columns=['targetnya'])\n",
        "\n",
        "y_test = test['targetnya']\n",
        "X_test = test.drop(columns=['targetnya'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PB1i2N4gyjb",
        "outputId": "1198dccb-28fc-4a05-c33f-e02c703b3632"
      },
      "outputs": [],
      "source": [
        "# Length before oversampling\n",
        "print(Counter(train['targetnya']), len(train))\n",
        "print(Counter(test['targetnya']), len(test))\n",
        "\n",
        "# Oversampling\n",
        "ov = SMOTE(random_state=42)\n",
        "X_train, y_train = ov.fit_resample(X_train, y_train)\n",
        "X_test, y_test = ov.fit_resample(X_test, y_test)\n",
        "\n",
        "# Length after oversampling\n",
        "print(Counter(y_train), len(y_train))\n",
        "print(Counter(y_test), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNuLu1vjgZC"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "rkjWtoIrhIDy",
        "outputId": "7f26f151-1e41-4cfc-8331-76933bcd3896"
      },
      "outputs": [],
      "source": [
        "# Train a Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcXVJeEghK-t",
        "outputId": "f1122e69-438c-47e0-90ce-a325af895d5b"
      },
      "outputs": [],
      "source": [
        "# Predict on the testing set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "oHWPMunAjwuP",
        "outputId": "8a5a4091-7db8-4e42-a831-966e97fe98fd"
      },
      "outputs": [],
      "source": [
        "cm = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "fig = cm.ax_.get_figure()\n",
        "fig.set_figwidth(12)\n",
        "fig.set_figheight(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5ZMWyKPji_d"
      },
      "source": [
        "## Model Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "zsGsP4ejjEv1",
        "outputId": "19e4881e-62ab-44ed-b125-9dbd31180077"
      },
      "outputs": [],
      "source": [
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance Analysis')\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis for better visualization\n",
        "plt.show()\n",
        "\n",
        "# Print the top influential features\n",
        "top_features = importance_df.head(10)  # Adjust the number of top features to display\n",
        "print(\"Top Influential Features:\")\n",
        "print(top_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25eIGewVmk4K"
      },
      "source": [
        "# Predict Data Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "g6jW2uyTmpnp",
        "outputId": "9842e657-4a0c-4bfb-f4f7-8980a230d01e"
      },
      "outputs": [],
      "source": [
        "data_to_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2T2knWvjoor"
      },
      "outputs": [],
      "source": [
        "# Prediction on the other data file\n",
        "predictions = rf_model.predict(data_to_predict)\n",
        "\n",
        "# Inverse transform the encoded categorical features to their original values\n",
        "for column in categorical_columns:\n",
        "    data_to_predict[column] = label_encoders[column].inverse_transform(data_to_predict[column])\n",
        "\n",
        "# Add the predictions to the 'data_to_predict' DataFrame\n",
        "data_to_predict['predicted_targetnya'] = predictions\n",
        "\n",
        "# Determine the number of rows in the DataFrame\n",
        "num_rows = data_to_predict.shape[0]\n",
        "\n",
        "# Add a new 'id' column with values ranging from 0 to num_rows-1\n",
        "data_to_predict['id'] = range(num_rows)\n",
        "\n",
        "# Rearrange the 'id' column to the front of the DataFrame\n",
        "data_to_predict = data_to_predict[['id'] + [col for col in data_to_predict.columns if col != 'id']]\n",
        "\n",
        "# Save the DataFrame with predictions to a CSV file\n",
        "data_to_predict.to_csv('data_with_predictions_rf_final.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
